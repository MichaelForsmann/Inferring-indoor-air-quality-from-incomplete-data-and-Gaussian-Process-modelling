{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "df699b35-56ba-4912-b1e3-0ca2e46de47d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from pyro import clear_param_store\n",
    "import pyro.contrib.gp as gp\n",
    "from pyro.nn import PyroSample\n",
    "import pyro.distributions as dist\n",
    "from pyro.infer import MCMC, NUTS, Predictive,HMC\n",
    "import torch\n",
    "import arviz as az"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d02f9498-d551-4041-ba4f-08c9f83604a8",
   "metadata": {},
   "source": [
    "### Importing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "90230fe6-0f6a-4898-be1f-5768cfcf3cfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warmup:   0%|▏                                        | 42/10000 [00:35,  1.20it/s, step size=1.22e-02, acc. prob=0.776]\n"
     ]
    }
   ],
   "source": [
    "train=pd.read_excel(r\"../data/chem_train.xlsx\")\n",
    "test=pd.read_excel(r\"../data/chem_test.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc2f902a-e9f8-4872-9130-9032f02d28b8",
   "metadata": {},
   "source": [
    "### Preparing data to gaussion process for formaldehyd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e546dad2-03b0-49cb-bf7b-ccb5accc14a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# putting data on gpu else cpu\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# remove Nan values \n",
    "train_formaldehyd=train.dropna(subset=\"formaldehyd\")\n",
    "# transfor tensor down to gpu \n",
    "X_form=torch.tensor(train_formaldehyd.corrected_week.values).float().to(device)\n",
    "y_form=torch.tensor(train_formaldehyd.formaldehyd.values).float().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b16a180-5a4b-4df0-bef8-e4583ac68843",
   "metadata": {},
   "source": [
    "### Defining model and priors "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1ce09057-e010-434d-b076-e71e26007374",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clearing varibles in pyro\n",
    "clear_param_store()\n",
    "# creating rbf kerneld for gaussion process \n",
    "rbf = gp.kernels.RBF(input_dim=1)\n",
    "\n",
    "# set the varience of the kernel to a half normal with mean as the std\n",
    "rbf.variance = PyroSample(dist.HalfNormal(torch.tensor(train.formaldehyd.mean())))\n",
    "# set low half normal prior due to farmaldehyd  being a \n",
    "rbf.lengthscale = PyroSample(dist.HalfNormal(torch.tensor(10.)))\n",
    "\n",
    "gpr = gp.models.GPRegression(X_form,y_form, rbf).to(device)\n",
    "gpr.noise = PyroSample(dist.HalfNormal(torch.tensor(10.)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcd0964a-1ca6-4a03-9593-73938ebc1af9",
   "metadata": {},
   "source": [
    "### Traning mcmc sampler and saving model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "30e49a8d-5881-4517-b33b-e79be8260aa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sample: 100%|██████████████████████████████████████| 10000/10000 [03:15, 51.20it/s, step size=7.38e-01, acc. prob=0.909]\n"
     ]
    }
   ],
   "source": [
    "nuts_kernel = NUTS(gpr.model)\n",
    "mcmc = MCMC(nuts_kernel,warmup_steps=8000, num_samples=2000,num_chains=1 )\n",
    "mcmc.run()\n",
    "torch.save(gpr, \"../models/form_seasonality\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f20b317-a68a-4aff-a741-d0674cd6cdd7",
   "metadata": {},
   "source": [
    "### Creating arviz dataset and save it "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c9130ecb-2e2a-4baf-a76f-c8604910aa52",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/michaelf/miniconda3/lib/python3.10/site-packages/arviz/data/io_pyro.py:158: UserWarning: Could not get vectorized trace, log_likelihood group will be omitted. Check your model vectorization or set log_likelihood=False\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'../Arviz_stats/mcmc_form_seasonality.json'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "posterior_samples = mcmc.get_samples(500)\n",
    "posterior_predictive= Predictive(gpr, posterior_samples)(X_form)\n",
    "prior = Predictive(gpr, num_samples=500)(X_form)\n",
    "\n",
    "pyro_data = az.from_pyro(mcmc,\n",
    "    prior=prior,\n",
    "    posterior_predictive=posterior_predictive,\n",
    "\n",
    ")\n",
    "az.to_json(pyro_data, \"../Arviz_stats/mcmc_form_seasonality.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b881ddc0-0c56-4533-9b02-89c3de675620",
   "metadata": {},
   "source": [
    "### Preparing data to gaussion process for formaldehyd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6504dc3f-7d89-469b-9285-fc4d187a9298",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_acetald=train.dropna(subset=\"acetald\")\n",
    "X_acetald=torch.tensor(train_acetald.corrected_week.values).float().to(device)\n",
    "y_acetald=torch.tensor(train_acetald.acetald.values).float().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66029884-aa01-4606-894c-72225ae706d1",
   "metadata": {},
   "source": [
    "### Defining model and priors "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "46a308b8-9143-47f6-b8ce-1776441b3c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "clear_param_store()\n",
    "rbf_bc = gp.kernels.RBF(input_dim=1)\n",
    "\n",
    "\n",
    "rbf_bc.variance = PyroSample(dist.HalfNormal(torch.tensor(train.acetald.mean())))\n",
    "\n",
    "rbf_bc.lengthscale = PyroSample(dist.HalfNormal(torch.tensor(10.)))\n",
    "gpr_bc = gp.models.GPRegression(X_acetald,y_acetald, rbf_bc).to(device)\n",
    "gpr_bc.noise = PyroSample(dist.HalfNormal(torch.tensor(10.)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92a43b0b-851d-4f8b-8d5a-1c667c9a4fe1",
   "metadata": {},
   "source": [
    "### Traning mcmc sampler and saving model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "659a808a-3c02-4830-ad3e-75eafa9a4b46",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sample: 100%|██████████████████████████████████████| 10000/10000 [03:17, 50.71it/s, step size=7.49e-01, acc. prob=0.913]\n"
     ]
    }
   ],
   "source": [
    "nuts_kernel_bc = NUTS(gpr_bc.model)\n",
    "mcmc_bc = MCMC(nuts_kernel_bc,warmup_steps=8000, num_samples=2000,num_chains=1)\n",
    "mcmc_bc.run()\n",
    "torch.save(gpr_bc, \"../models/acetald_seasonality\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53137c3a-bc87-41ab-b01e-e77b9a13577a",
   "metadata": {},
   "source": [
    "### making Arviz dataset for acetald "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b9cd439d-05a5-44af-b69b-d83a286e6786",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/michaelf/miniconda3/lib/python3.10/site-packages/arviz/data/io_pyro.py:158: UserWarning: Could not get vectorized trace, log_likelihood group will be omitted. Check your model vectorization or set log_likelihood=False\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'../Arviz_stats/mcmc_acetald_seasonality.json'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posterior_samples_bc = mcmc_bc.get_samples(500)\n",
    "posterior_predictive_bc = Predictive(gpr_bc, posterior_samples_bc)(X_acetald)\n",
    "prior_bc = Predictive(gpr_bc, num_samples=500)(X_acetald)\n",
    "\n",
    "pyro_data_bc = az.from_pyro(mcmc_bc,\n",
    "    prior=prior_bc,\n",
    "    posterior_predictive=posterior_predictive_bc,\n",
    "\n",
    ")\n",
    "az.to_json(pyro_data_bc, \"../Arviz_stats/mcmc_acetald_seasonality.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecb759a7-ab3d-497e-835b-43947554a2eb",
   "metadata": {},
   "source": [
    "### Preparing data to gaussion process for acetone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "293f3e63-4447-4d06-a29a-f9a829c031b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_acetone=train.dropna(subset=\"acetone\")\n",
    "X_acetone=torch.tensor(train_acetone.corrected_week.values).float().to(device)\n",
    "y_acetone=torch.tensor(train_acetone.acetone.values).float().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f015dff7-5eae-43c4-ad5f-da253dd3935b",
   "metadata": {},
   "source": [
    "### Acetone define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9dc4f987-2f69-4425-9003-e3d95bd0397c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sample: 100%|██████████████████████████████████████| 10000/10000 [03:41, 45.18it/s, step size=7.16e-01, acc. prob=0.888]\n"
     ]
    }
   ],
   "source": [
    "clear_param_store()\n",
    "rbf_ac = gp.kernels.RBF(input_dim=1)\n",
    "rbf_ac.variance = PyroSample(dist.HalfNormal(torch.tensor(train.acetone.mean())))\n",
    "rbf_ac.lengthscale = PyroSample(dist.HalfNormal(torch.tensor(10.)))\n",
    "\n",
    "gpr_ac = gp.models.GPRegression(X_acetone,y_acetone, rbf_ac).to(device)\n",
    "gpr_ac.noise = PyroSample(dist.HalfNormal(torch.tensor(10.)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a0996ac-a262-4d92-90a8-324598183345",
   "metadata": {},
   "source": [
    "### Train mcmc and gaussian sample Acetone\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5779b4f-75da-4a47-8286-702342ad0d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "nuts_kernel_ac = NUTS(gpr_ac.model)\n",
    "\n",
    "mcmc_ac = MCMC(nuts_kernel_ac,warmup_steps=8000, num_samples=2000,num_chains=1)\n",
    "\n",
    "mcmc_ac.run()\n",
    "torch.save(gpr_ac, \"../models/acetone_seasonality\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6210bcf3-2ac4-4990-bac5-96f9b0d35b53",
   "metadata": {},
   "source": [
    "### Make parametric stats for the mcmc sampler and save in json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3c694586-11d3-497a-a16e-6d00e899f7ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/michaelf/miniconda3/lib/python3.10/site-packages/arviz/data/io_pyro.py:158: UserWarning: Could not get vectorized trace, log_likelihood group will be omitted. Check your model vectorization or set log_likelihood=False\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'../Arviz_stats/mcmc_acetone_seasonality.json'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posterior_samples_ac = mcmc_ac.get_samples(500)\n",
    "posterior_predictive_ac = Predictive(gpr_bc, posterior_samples_ac)(X_acetone)\n",
    "prior_ac = Predictive(gpr_ac, num_samples=500)(X_acetone)\n",
    "\n",
    "pyro_data_ac = az.from_pyro(mcmc_ac,\n",
    "    prior=prior_ac,\n",
    "    posterior_predictive=posterior_predictive_ac,\n",
    "\n",
    ")\n",
    "az.to_json(pyro_data_ac, \"../Arviz_stats/mcmc_acetone_seasonality.json\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
